diff --git a/LLMS.txt b/LLMS.txt
index f52fa82..bd450e9 100644
--- a/LLMS.txt
+++ b/LLMS.txt
@@ -2532,13 +2532,13 @@ Some key notes:
 - **Parameters**
   - `self`
 
-**Function:** `Workflow.run_async(self) -> str`
+**Function:** `Workflow.run_async(self) -> WorkflowExecution`
 
-- **Description**: Run the workflow asynchronously and return a workflow ID. This creates an async task that will be executed through the executor and returns immediately with a workflow run ID that can be used to check status, resume, or cancel. Args: *args: Positional arguments to pass to the run method **kwargs: Keyword arguments to pass to the run method Returns: str: A unique workflow ID that can be used to reference this workflow instance
+- **Description**: Run the workflow asynchronously and return the WorkflowExecution. This creates an async task that will be executed through the executor and returns immediately with a WorkflowExecution with run ID that can be used to check status, resume, or cancel. Args: *args: Positional arguments to pass to the run method **kwargs: Keyword arguments to pass to the run method Returns: str: A unique workflow ID that can be used to reference this workflow instance
 - **Parameters**
   - `self`
 - **Returns**
-  - `str`: str: A unique workflow ID that can be used to reference this workflow instance
+  - `WorkflowExecution`: WorkflowExecution: The execution details including run ID and workflow ID
 
 **Function:** `Workflow._execute_workflow()`
 
@@ -7326,4 +7326,3 @@ using Anthropic's API as the LLM.
 - **Description**: MCP version of the OpenAI Swarm class (https://github.com/openai/swarm.), using OpenAI's ChatCompletion as the LLM.
 
 **Function:** `OpenAISwarm.generate(self, message, request_params: RequestParams | None = None)`
-
diff --git a/examples/mcp_agent_server/asyncio/client.py b/examples/mcp_agent_server/asyncio/client.py
index c232319..5bbe01f 100644
--- a/examples/mcp_agent_server/asyncio/client.py
+++ b/examples/mcp_agent_server/asyncio/client.py
@@ -1,8 +1,10 @@
 import asyncio
+import json
 import time
 from mcp.types import CallToolResult
 from mcp_agent.app import MCPApp
 from mcp_agent.config import MCPServerSettings
+from mcp_agent.executor.workflow import WorkflowExecution
 from mcp_agent.mcp.gen_client import gen_client
 
 
@@ -51,8 +53,11 @@ async def main():
                 },
             )
 
-            run_id: str = run_result.content[0].text
-            logger.info(f"Started BasicAgentWorkflow-run. workflow run ID={run_id}")
+            execution = WorkflowExecution(**json.loads(run_result.content[0].text))
+            run_id = execution.run_id
+            logger.info(
+                f"Started BasicAgentWorkflow-run. workflow ID={execution.workflow_id}, run ID={run_id}"
+            )
 
             # Wait for the workflow to complete
             while True:
diff --git a/examples/mcp_agent_server/temporal/client.py b/examples/mcp_agent_server/temporal/client.py
index a41644e..634dea5 100644
--- a/examples/mcp_agent_server/temporal/client.py
+++ b/examples/mcp_agent_server/temporal/client.py
@@ -1,8 +1,10 @@
 import asyncio
+import json
 import time
 from mcp.types import CallToolResult
 from mcp_agent.app import MCPApp
 from mcp_agent.config import MCPServerSettings
+from mcp_agent.executor.workflow import WorkflowExecution
 from mcp_agent.mcp.gen_client import gen_client
 
 
@@ -36,8 +38,11 @@ async def main():
                 },
             )
 
-            run_id: str = run_result.content[0].text
-            logger.info(f"Started BasicAgentWorkflow-run. workflow run ID={run_id}")
+            execution = WorkflowExecution(**json.loads(run_result.content[0].text))
+            run_id = execution.run_id
+            logger.info(
+                f"Started BasicAgentWorkflow-run. workflow ID={execution.workflow_id}, run ID={run_id}"
+            )
 
             # Wait for the workflow to complete
             while True:
diff --git a/src/mcp_agent/executor/temporal/workflow_registry.py b/src/mcp_agent/executor/temporal/workflow_registry.py
index 7961811..966443a 100644
--- a/src/mcp_agent/executor/temporal/workflow_registry.py
+++ b/src/mcp_agent/executor/temporal/workflow_registry.py
@@ -138,7 +138,11 @@ class TemporalWorkflowRegistry(WorkflowRegistry):
         self, run_id: str, workflow_id: str | None = None
     ) -> Optional[Dict[str, Any]]:
         workflow = await self.get_workflow(run_id)
-        workflow_id = workflow.name if workflow and workflow_id is None else workflow_id
+        workflow_id = (
+            (workflow.id or workflow.name)
+            if workflow and workflow_id is None
+            else workflow_id
+        )
 
         if not workflow_id:
             # In Temporal, we need both workflow_id and run_id to target a specific run
@@ -168,10 +172,11 @@ class TemporalWorkflowRegistry(WorkflowRegistry):
         for run_id, workflow in self._local_workflows.items():
             # Get the workflow status directly to have consistent behavior
             status = await workflow.get_status()
+            workflow_id = workflow.id or workflow.name
 
             # Query Temporal for the status
             temporal_status = await self._get_temporal_workflow_status(
-                workflow_id=workflow.name, run_id=run_id
+                workflow_id=workflow_id, run_id=run_id
             )
 
             status["temporal"] = temporal_status
diff --git a/src/mcp_agent/executor/workflow.py b/src/mcp_agent/executor/workflow.py
index 2448040..ecffed3 100644
--- a/src/mcp_agent/executor/workflow.py
+++ b/src/mcp_agent/executor/workflow.py
@@ -59,6 +59,16 @@ class WorkflowResult(BaseModel, Generic[T]):
     end_time: float | None = None
 
 
+class WorkflowExecution(BaseModel):
+    """
+    Represents a workflow execution with its run ID and workflow ID.
+    This is used to track the execution of workflows.
+    """
+
+    workflow_id: str
+    run_id: str | None = None
+
+
 class Workflow(ABC, Generic[T], ContextDependent):
     """
     Base class for user-defined workflows.
@@ -176,20 +186,20 @@ class Workflow(ABC, Generic[T], ContextDependent):
         # The run task will be cancelled in the run_async method
         return signal
 
-    async def run_async(self, *args, **kwargs) -> str:
+    async def run_async(self, *args, **kwargs) -> "WorkflowExecution":
         """
-        Run the workflow asynchronously and return a workflow ID.
+        Run the workflow asynchronously and return the WorkflowExecution.
 
         This creates an async task that will be executed through the executor
-        and returns immediately with a workflow run ID that can be used to
-        check status, resume, or cancel.
+        and returns immediately with a WorkflowExecution with run ID that can
+        be used to check status, resume, or cancel.
 
         Args:
             *args: Positional arguments to pass to the run method
             **kwargs: Keyword arguments to pass to the run method
 
         Returns:
-            str: A unique workflow ID that can be used to reference this workflow instance
+            WorkflowExecution: The execution details including run ID and workflow ID
         """
 
         import asyncio
@@ -211,10 +221,15 @@ class Workflow(ABC, Generic[T], ContextDependent):
             handle = await executor.start_workflow(self.name, *args, **kwargs)
             self._workflow_id = handle.id
             self._run_id = handle.result_run_id or handle.run_id
-            self._logger.debug(
-                f"Workflow started with workflow ID: {self._workflow_id}, run ID: {self._run_id}"
+        else:
+            raise ValueError(
+                f"Unsupported execution engine: {self.context.config.execution_engine}"
             )
 
+        self._logger.debug(
+            f"Workflow started with workflow ID: {self._workflow_id}, run ID: {self._run_id}"
+        )
+
         # Define the workflow execution function
         async def _execute_workflow():
             try:
@@ -295,7 +310,10 @@ class Workflow(ABC, Generic[T], ContextDependent):
                 task=self._run_task,
             )
 
-        return self._run_id
+        return WorkflowExecution(
+            run_id=self._run_id,
+            workflow_id=self._workflow_id,
+        )
 
     async def resume(
         self, signal_name: str | None = "resume", payload: str | None = None
diff --git a/src/mcp_agent/server/app_server.py b/src/mcp_agent/server/app_server.py
index fa974ed..c2ed354 100644
--- a/src/mcp_agent/server/app_server.py
+++ b/src/mcp_agent/server/app_server.py
@@ -178,7 +178,7 @@ def create_mcp_server_for_app(app: MCPApp) -> FastMCP:
         ctx: MCPContext,
         workflow_name: str,
         run_parameters: Dict[str, Any] | None = None,
-    ) -> str:
+    ) -> Dict[str, str]:
         """
         Run a workflow with the given name.
 
@@ -188,7 +188,7 @@ def create_mcp_server_for_app(app: MCPApp) -> FastMCP:
                 workflows/list method will return the run_parameters schema for each workflow.
 
         Returns:
-            The run ID of the started workflow run, which can be passed to
+            A dict with workflow_id and run_id for the started workflow run, can be passed to
             workflows/get_status, workflows/resume, and workflows/cancel.
         """
         return await _workflow_run(ctx, workflow_name, run_parameters)
@@ -327,7 +327,7 @@ def create_workflow_specific_tools(
     @mcp.tool(
         name=f"workflows-{workflow_name}-run",
         description=f"""
-        Run the '{workflow_name}' workflow and get a run ID back.
+        Run the '{workflow_name}' workflow and get a dict with workflow_id and run_id back.
         Workflow Description: {workflow_cls.__doc__}
 
         {run_fn_tool.description}
@@ -341,7 +341,7 @@ def create_workflow_specific_tools(
     async def run(
         ctx: MCPContext,
         run_parameters: Dict[str, Any] | None = None,
-    ) -> Dict[str, Any]:
+    ) -> Dict[str, str]:
         return await _workflow_run(ctx, workflow_name, run_parameters)
 
     @mcp.tool(
@@ -354,7 +354,7 @@ def create_workflow_specific_tools(
         """,
     )
     async def get_status(ctx: MCPContext, run_id: str) -> Dict[str, Any]:
-        return await _workflow_status(ctx, run_id=run_id, workflow_id=workflow_name)
+        return await _workflow_status(ctx, run_id=run_id, workflow_name=workflow_name)
 
 
 # endregion
@@ -404,42 +404,45 @@ def _get_server_descriptions_as_string(
 
 async def _workflow_run(
     ctx: MCPContext,
-    workflow_id: str,
+    workflow_name: str,
     run_parameters: Dict[str, Any] | None = None,
-) -> str:
+) -> Dict[str, str]:
     server_context: ServerContext = ctx.request_context.lifespan_context
 
-    if workflow_id not in server_context.workflows:
-        raise ToolError(f"Workflow '{workflow_id}' not found.")
+    if workflow_name not in server_context.workflows:
+        raise ToolError(f"Workflow '{workflow_name}' not found.")
 
     # Get the workflow class
-    workflow_cls = server_context.workflows[workflow_id]
+    workflow_cls = server_context.workflows[workflow_name]
 
     # Create and initialize the workflow instance using the factory method
     try:
         # Create workflow instance
         workflow = await workflow_cls.create(
-            name=workflow_id, context=server_context.context
+            name=workflow_name, context=server_context.context
         )
 
         run_parameters = run_parameters or {}
 
         # Run the workflow asynchronously and get its ID
-        run_id = await workflow.run_async(**run_parameters)
+        execution = await workflow.run_async(**run_parameters)
 
         logger.info(
-            f"Workflow {workflow_id} started with run ID {run_id}. Parameters: {run_parameters}"
+            f"Workflow {workflow_name} started with workflow ID {execution.workflow_id} and run ID {execution.run_id}. Parameters: {run_parameters}"
         )
 
-        return run_id
+        return {
+            "workflow_id": execution.workflow_id,
+            "run_id": execution.run_id,
+        }
 
     except Exception as e:
-        logger.error(f"Error creating workflow {workflow_id}: {str(e)}")
-        raise ToolError(f"Error creating workflow {workflow_id}: {str(e)}") from e
+        logger.error(f"Error creating workflow {workflow_name}: {str(e)}")
+        raise ToolError(f"Error creating workflow {workflow_name}: {str(e)}") from e
 
 
 async def _workflow_status(
-    ctx: MCPContext, run_id: str, workflow_id: str | None = None
+    ctx: MCPContext, run_id: str, workflow_name: str | None = None
 ) -> Dict[str, Any]:
     server_context: ServerContext = ctx.request_context.lifespan_context
     workflow_registry: WorkflowRegistry = server_context.workflow_registry
@@ -447,6 +450,9 @@ async def _workflow_status(
     if not workflow_registry:
         raise ToolError("Workflow registry not found for MCPApp Server.")
 
+    workflow = await workflow_registry.get_workflow(run_id)
+    workflow_id = workflow.id if workflow and workflow.id else workflow_name
+
     status = await workflow_registry.get_workflow_status(
         run_id=run_id, workflow_id=workflow_id
     )
diff --git a/tests/executor/test_workflow.py b/tests/executor/test_workflow.py
index ababc55..d154ab9 100644
--- a/tests/executor/test_workflow.py
+++ b/tests/executor/test_workflow.py
@@ -131,8 +131,9 @@ class TestWorkflowAsyncMethods:
             await asyncio.Future()
 
         workflow.executor.wait_for_signal = AsyncMock(side_effect=never_return)
-        run_id = await workflow.run_async()
-        assert run_id == "uuid-123"
+        execution = await workflow.run_async()
+        assert execution.run_id == "uuid-123"
+        assert execution.workflow_id == "TestWorkflow"
         assert workflow._run_id == "uuid-123"
         # verify status transitions
         assert workflow.state.status == "scheduled"
@@ -170,8 +171,9 @@ class TestWorkflowAsyncMethods:
             workflows.append(wf)
 
         # Start all workflows concurrently
-        run_id_tasks = [wf.run_async() for wf in workflows]
-        run_ids = await asyncio.gather(*run_id_tasks)
+        execution_tasks = [wf.run_async() for wf in workflows]
+        executions = await asyncio.gather(*execution_tasks)
+        run_ids = [exec.run_id for exec in executions]
 
         # Verify each workflow has a unique run_id
         assert len(set(run_ids)) == 3, "All run_ids should be unique"
@@ -229,7 +231,9 @@ class TestWorkflowAsyncMethods:
             workflows.append(wf)
 
         # Start all workflows
-        run_ids = await asyncio.gather(*[wf.run_async() for wf in workflows])
+        execution_tasks = [wf.run_async() for wf in workflows]
+        executions = await asyncio.gather(*execution_tasks)
+        run_ids = [exec.run_id for exec in executions]
 
         # Verify each workflow has a unique run_id
         assert len(set(run_ids)) == 3, "All run_ids should be unique"
